{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4CzZ1yjK1rw/ZmDKre4kD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmehtiyev2019/llm-api-tm/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "!pip install openai\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "2Knqed7BRp92",
        "outputId": "662489ce-9e49-49ad-ffb3-0b66a5f732bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/221.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.8\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
            "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "api_key_path = '/content/drive/My Drive/api_key.txt'  # Update this path to the location of your API key file\n",
        "with open(api_key_path, 'r') as file:\n",
        "    openai_api_key = file.read().strip()\n"
      ],
      "metadata": {
        "id": "TgoWFQcL6DT-",
        "outputId": "dbdf7e94-661c-4142-87e1-753614fe7e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from langchain.chains.openai_functions import (\n",
        "    create_openai_fn_chain,\n",
        "    create_openai_fn_runnable,\n",
        "    create_structured_output_chain,\n",
        "    create_structured_output_runnable,\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from typing import Sequence\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(api_key=openai_api_key,model=\"gpt-4\", temperature=0)\n",
        "\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a world class algorithm for extracting information in structured formats.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following input: {input}\",\n",
        "        ),\n",
        "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "json_schema = {\n",
        "    \"title\": \"Person\",\n",
        "    \"description\": \"Identifying information about a person.\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
        "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
        "        \"fav_food\": {\n",
        "            \"title\": \"Fav Food\",\n",
        "            \"description\": \"The person's favorite food\",\n",
        "            \"type\": \"string\",\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\"],\n",
        "}\n",
        "\n",
        "\n",
        "runnable = create_structured_output_runnable(json_schema, llm, prompt)\n",
        "runnable.invoke({\"input\": \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"})"
      ],
      "metadata": {
        "id": "jdVpymti3AsB",
        "outputId": "e8844e50-285f-476b-f3b8-257348ee4352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Sally', 'age': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "from typing import Optional\n",
        "from langchain.chains.openai_functions import (\n",
        "    create_openai_fn_chain,\n",
        "    create_openai_fn_runnable,\n",
        "    create_structured_output_chain,\n",
        "    create_structured_output_runnable,\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from typing import Sequence\n",
        "from langchain.pydantic_v1 import BaseModel, Field"
      ],
      "metadata": {
        "id": "a92qr5xXtp02"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = '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'\n",
        "\n",
        "# # Initialize LangChain with OpenAI LLM\n",
        "# llm = OpenAI(\n",
        "#     api_key=openai_api_key,\n",
        "#     model_name=\"text-davinci-003\",\n",
        "#     temperature=0.2,\n",
        "#     max_tokens=64\n",
        "# )\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Identifying information about a person.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The person's name\")\n",
        "    age: int = Field(..., description=\"The person's age\")\n",
        "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
        "\n",
        "\n",
        "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
        "llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a world class algorithm for extracting information in structured formats.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following input: {input}\",\n",
        "        ),\n",
        "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "runnable = create_structured_output_runnable(Person, llm, prompt)\n",
        "runnable.invoke({\"input\": \"Sally is 13\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "pZRdvQzap5Vd",
        "outputId": "a99a6bb5-19a2-487e-d897-3f4f659653e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='Sally', age=13, fav_food=None)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Person(BaseModel):\n",
        "    \"\"\"Identifying information about a person.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The person's name\")\n",
        "    age: int = Field(..., description=\"The person's age\")\n",
        "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZSHmsfo2KxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
        "llm = ChatOpenAI(api_key=openai_api_key,model=\"gpt-4\", temperature=0)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a world class algorithm for extracting information in structured formats.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following input: {input}\",\n",
        "        ),\n",
        "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "runnable = create_structured_output_runnable(Person, llm, prompt)\n",
        "runnable.invoke({\"input\": \"Sally is 13\"})"
      ],
      "metadata": {
        "id": "wKILIqUfvJe_",
        "outputId": "5f0f18b4-a793-4b15-fdfd-2acce46dd9e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='Sally', age=13, fav_food='Unknown')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class People(BaseModel):\n",
        "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
        "\n",
        "    people: Sequence[Person] = Field(..., description=\"The people in the text\")\n",
        "\n",
        "\n",
        "runnable = create_structured_output_runnable(People, llm, prompt)\n",
        "runnable.invoke(\n",
        "    {\n",
        "        \"input\": \"Sally is 13, Joey just turned 12 and loves spinach. Caroline is 10 years older than Sally.\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "ajyvZTbyvWWY",
        "outputId": "8843822f-1755-40b1-eb5b-c64f67bd4372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "People(people=[Person(name='Sally', age=13, fav_food=''), Person(name='Joey', age=12, fav_food='spinach'), Person(name='Caroline', age=23, fav_food='')])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema = {\n",
        "    \"title\": \"Person\",\n",
        "    \"description\": \"Identifying information about a person.\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
        "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
        "        \"fav_food\": {\n",
        "            \"title\": \"Fav Food\",\n",
        "            \"description\": \"The person's favorite food\",\n",
        "            \"type\": \"string\",\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\"],\n",
        "}"
      ],
      "metadata": {
        "id": "bYj9FA6JvdHK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = create_structured_output_runnable(json_schema, llm, prompt)\n",
        "runnable.invoke({\"input\": \"Sally is 13\"})"
      ],
      "metadata": {
        "id": "f6FyNgpxvcBe",
        "outputId": "9c3adb40-6b81-4748-ee6e-c0d337091579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Sally', 'age': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_structured_output_chain(Person, llm, prompt, verbose=True)\n",
        "chain.run(\"Sally is 13\")"
      ],
      "metadata": {
        "id": "wklUO5HGugYX",
        "outputId": "81e9bf10-3088-4f2e-edcc-6b697c5b6020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for extracting information in structured formats.\n",
            "Human: Use the given format to extract information from the following input: Sally is 13\n",
            "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='Sally', age=13, fav_food='Unknown')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RecordPerson(BaseModel):\n",
        "    \"\"\"Record some identifying information about a pe.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The person's name\")\n",
        "    age: int = Field(..., description=\"The person's age\")\n",
        "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
        "\n",
        "\n",
        "class RecordDog(BaseModel):\n",
        "    \"\"\"Record some identifying information about a dog.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The dog's name\")\n",
        "    color: str = Field(..., description=\"The dog's color\")\n",
        "    fav_food: Optional[str] = Field(None, description=\"The dog's favorite food\")"
      ],
      "metadata": {
        "id": "FRSQayNMxdap"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.openai_functions import (\n",
        "    convert_to_openai_function,\n",
        "    get_openai_output_parser,\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a world class algorithm for recording entities.\"),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Make calls to the relevant function to record the entities in the following input: {input}\",\n",
        "        ),\n",
        "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "openai_functions = [convert_to_openai_function(f) for f in (RecordPerson, RecordDog)]\n",
        "llm_kwargs = {\"functions\": openai_functions}\n",
        "if len(openai_functions) == 1:\n",
        "    llm_kwargs[\"function_call\"] = {\"name\": openai_functions[0][\"name\"]}\n",
        "output_parser = get_openai_output_parser((RecordPerson, RecordDog))\n",
        "runnable = prompt | llm.bind(**llm_kwargs) | output_parser"
      ],
      "metadata": {
        "id": "re9HL3FExmV8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable.invoke({\"input\": \"Harry was a chubby brown beagle who loved chicken\"})"
      ],
      "metadata": {
        "id": "fjAqtGeQxoqJ",
        "outputId": "312fcf14-bd77-414a-bc6d-79bcbe5c1360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecordDog(name='Harry', color='brown', fav_food='chicken')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = create_openai_fn_runnable([RecordPerson, RecordDog], llm, prompt)\n",
        "runnable.invoke({\"input\": \"Harry was a chubby brown beagle who loved chicken\"})"
      ],
      "metadata": {
        "id": "YO8z4QZcxrJn",
        "outputId": "31b98d14-adb4-47b6-a666-f2bac1844cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecordDog(name='Harry', color='brown', fav_food='chicken')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Python functions\n",
        "\n",
        "We can pass in functions as Pydantic classes, directly as OpenAI function dicts, or Python functions. To pass Python function in directly, we’ll want to make sure our parameters have type hints, we have a docstring, and we use Google Python style docstrings to describe the parameters.\n",
        "\n",
        "NOTE: To use Python functions, make sure the function arguments are of primitive types (str, float, int, bool) or that they are Pydantic objects."
      ],
      "metadata": {
        "id": "U75q5Nctx19D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OptionalFavFood(BaseModel):\n",
        "    \"\"\"Either a food or null.\"\"\"\n",
        "\n",
        "    food: Optional[str] = Field(\n",
        "        None,\n",
        "        description=\"Either the name of a food or null. Should be null if the food isn't known.\",\n",
        "    )\n",
        "\n",
        "\n",
        "def record_person(name: str, age: int, fav_food: OptionalFavFood) -> str:\n",
        "    \"\"\"Record some basic identifying information about a person.\n",
        "\n",
        "    Args:\n",
        "        name: The person's name.\n",
        "        age: The person's age in years.\n",
        "        fav_food: An OptionalFavFood object that either contains the person's favorite food or a null value. Food should be null if it's not known.\n",
        "    \"\"\"\n",
        "    return f\"Recording person {name} of age {age} with favorite food {fav_food.food}!\"\n",
        "\n",
        "\n",
        "runnable = create_openai_fn_runnable([record_person], llm, prompt)\n",
        "runnable.invoke(\n",
        "    {\n",
        "        \"input\": \"The most important thing to remember about Tommy, my 12 year old, is that he'll do anything for apple pie.\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "aLtOikOtxuDV",
        "outputId": "789da24e-2258-44b8-f32a-af16cc272aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Tommy', 'age': 12, 'fav_food': {'food': 'apple pie'}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def record_dog(name: str, color: str, fav_food: OptionalFavFood) -> str:\n",
        "    \"\"\"Record some basic identifying information about a dog.\n",
        "\n",
        "    Args:\n",
        "        name: The dog's name.\n",
        "        color: The dog's color.\n",
        "        fav_food: An OptionalFavFood object that either contains the dog's favorite food or a null value. Food should be null if it's not known.\n",
        "    \"\"\"\n",
        "    return f\"Recording dog {name} of color {color} with favorite food {fav_food}!\"\n",
        "\n",
        "\n",
        "runnable = create_openai_fn_runnable([record_person, record_dog], llm, prompt)\n",
        "runnable.invoke(\n",
        "    {\n",
        "        \"input\": \"I can't find my dog Henry anywhere, he's a small brown beagle. Could you send a message about him?\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "wRG8InyHx6vd",
        "outputId": "49f7a296-6a86-4ab3-8980-c604c5d5dc38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arguments': {'name': 'Henry', 'color': 'brown', 'fav_food': {'food': None}},\n",
              " 'name': 'record_dog'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Legacy] LLMChain-based approach"
      ],
      "metadata": {
        "id": "7nNGAeBbyJra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = create_openai_fn_chain([RecordPerson, RecordDog], llm, prompt, verbose=True)\n",
        "chain.run(\"Harry was a chubby brown beagle who loved chicken\")"
      ],
      "metadata": {
        "id": "oTvM4QaxyAIF",
        "outputId": "ff2090eb-d698-4845-c936-ee1228096ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a world class algorithm for recording entities.\n",
            "Human: Make calls to the relevant function to record the entities in the following input: Harry was a chubby brown beagle who loved chicken\n",
            "Human: Tip: Make sure to answer in the correct format\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecordDog(name='Harry', color='brown', fav_food='chicken')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYBagBTJyMmX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}